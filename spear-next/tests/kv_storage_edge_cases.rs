//! KV Storage Edge Cases and Error Handling Tests
//! KVå­˜å‚¨è¾¹ç•Œæƒ…å†µå’Œé”™è¯¯å¤„ç†æµ‹è¯•
//!
//! This module contains tests for edge cases, error conditions, and boundary scenarios
//! to ensure robust behavior across all KV storage backends.
//! æ­¤æ¨¡å—åŒ…å«è¾¹ç•Œæƒ…å†µã€é”™è¯¯æ¡ä»¶å’Œè¾¹ç•Œåœºæ™¯çš„æµ‹è¯•ï¼Œä»¥ç¡®ä¿æ‰€æœ‰KVå­˜å‚¨åç«¯çš„å¥å£®è¡Œä¸ºã€‚


use std::sync::Arc;
use std::time::Duration;
use tokio::time::timeout;
use tempfile::TempDir;

use spear_next::storage::{KvStoreConfig, DefaultKvStoreFactory, KvStoreFactory};


/// Test utilities for edge case testing
/// è¾¹ç•Œæƒ…å†µæµ‹è¯•çš„æµ‹è¯•å·¥å…·
mod test_utils {
    use super::*;

    /// Create test configurations for all supported backends
    /// ä¸ºæ‰€æœ‰æ”¯æŒçš„åç«¯åˆ›å»ºæµ‹è¯•é…ç½®
    pub fn create_test_configs() -> Vec<(&'static str, KvStoreConfig, Option<TempDir>)> {
        let mut configs = vec![
            ("memory", KvStoreConfig::memory(), None),
        ];

        #[cfg(feature = "sled")]
        {
            let temp_dir = TempDir::new().unwrap();
            let sled_config = KvStoreConfig::sled(temp_dir.path().to_str().unwrap());
            configs.push(("sled", sled_config, Some(temp_dir)));
        }

        #[cfg(feature = "rocksdb")]
        {
            let temp_dir = TempDir::new().unwrap();
            let rocksdb_config = KvStoreConfig::rocksdb(temp_dir.path().to_str().unwrap());
            configs.push(("rocksdb", rocksdb_config, Some(temp_dir)));
        }

        configs
    }

    /// Generate problematic keys for testing
    /// ç”Ÿæˆç”¨äºæµ‹è¯•çš„é—®é¢˜é”®
    pub fn generate_problematic_keys() -> Vec<String> {
        vec![
            "".to_string(),                           // Empty key / ç©ºé”®
            " ".to_string(),                          // Space key / ç©ºæ ¼é”®
            "\n".to_string(),                         // Newline key / æ¢è¡Œé”®
            "\t".to_string(),                         // Tab key / åˆ¶è¡¨ç¬¦é”®
            "\0".to_string(),                         // Null byte / ç©ºå­—èŠ‚
            "key\0with\0nulls".to_string(),          // Key with null bytes / åŒ…å«ç©ºå­—èŠ‚çš„é”®
            "key\nwith\nnewlines".to_string(),       // Key with newlines / åŒ…å«æ¢è¡Œçš„é”®
            "key\twith\ttabs".to_string(),           // Key with tabs / åŒ…å«åˆ¶è¡¨ç¬¦çš„é”®
            "key with spaces".to_string(),           // Key with spaces / åŒ…å«ç©ºæ ¼çš„é”®
            "key/with/slashes".to_string(),          // Key with slashes / åŒ…å«æ–œæ çš„é”®
            "key\\with\\backslashes".to_string(),    // Key with backslashes / åŒ…å«åæ–œæ çš„é”®
            "key:with:colons".to_string(),           // Key with colons / åŒ…å«å†’å·çš„é”®
            "key@with@symbols".to_string(),          // Key with symbols / åŒ…å«ç¬¦å·çš„é”®
            "é”®_with_ä¸­æ–‡".to_string(),               // Key with Chinese characters / åŒ…å«ä¸­æ–‡å­—ç¬¦çš„é”®
            "ğŸ”‘_emoji_key".to_string(),              // Key with emoji / åŒ…å«è¡¨æƒ…ç¬¦å·çš„é”®
            "very_long_key_".repeat(100),            // Very long key / å¾ˆé•¿çš„é”®
        ]
    }

    /// Generate problematic values for testing
    /// ç”Ÿæˆç”¨äºæµ‹è¯•çš„é—®é¢˜å€¼
    pub fn generate_problematic_values() -> Vec<String> {
        vec![
            "".to_string(),                                    // Empty value / ç©ºå€¼
            " ".to_string(),                                   // Space value / ç©ºæ ¼å€¼
            "\n".to_string(),                                  // Newline value / æ¢è¡Œå€¼
            "\t".to_string(),                                  // Tab value / åˆ¶è¡¨ç¬¦å€¼
            "\0".to_string(),                                  // Null byte / ç©ºå­—èŠ‚
            "value\0with\0nulls".to_string(),                 // Value with null bytes / åŒ…å«ç©ºå­—èŠ‚çš„å€¼
            "value\nwith\nnewlines".to_string(),              // Value with newlines / åŒ…å«æ¢è¡Œçš„å€¼
            "value\twith\ttabs".to_string(),                  // Value with tabs / åŒ…å«åˆ¶è¡¨ç¬¦çš„å€¼
            "value with spaces".to_string(),                  // Value with spaces / åŒ…å«ç©ºæ ¼çš„å€¼
            "å€¼_with_ä¸­æ–‡_characters".to_string(),             // Value with Chinese / åŒ…å«ä¸­æ–‡çš„å€¼
            "ğŸ’_emoji_value_ğŸš€".to_string(),                  // Value with emoji / åŒ…å«è¡¨æƒ…ç¬¦å·çš„å€¼
            "x".repeat(1024 * 1024),                         // 1MB value / 1MBå€¼
            "y".repeat(10 * 1024 * 1024),                    // 10MB value / 10MBå€¼
            serde_json::to_string(&(0..1000).collect::<Vec<i32>>()).unwrap(), // JSON data / JSONæ•°æ®
        ]
    }
}

/// Test empty and whitespace keys
/// æµ‹è¯•ç©ºé”®å’Œç©ºç™½é”®
#[tokio::test]
async fn test_empty_and_whitespace_keys() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing empty and whitespace keys for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        let problematic_keys = test_utils::generate_problematic_keys();
        
        for key in &problematic_keys {
            let value = format!("value_for_key_{}", key.len());
            
            // Test put operation
            // æµ‹è¯•è®¾ç½®æ“ä½œ
            let value_bytes = value.as_bytes().to_vec();
            let put_result = store.put(key, &value_bytes).await;
            assert!(put_result.is_ok(), "Failed to put key '{}' for backend {}: {:?}", 
                    key.escape_debug(), backend_name, put_result);
            
            // Test get operation
            // æµ‹è¯•è·å–æ“ä½œ
            let get_result = store.get(&key.to_string()).await;
            assert!(get_result.is_ok(), "Failed to get key '{}' for backend {}: {:?}", 
                    key.escape_debug(), backend_name, get_result);
            
            let retrieved_value = get_result.unwrap();
            assert_eq!(retrieved_value, Some(value.as_bytes().to_vec()), 
                      "Value mismatch for key '{}' in backend {}", key.escape_debug(), backend_name);
            
            // Test exists operation
            // æµ‹è¯•å­˜åœ¨æ€§æ“ä½œ
            let exists_result = store.exists(key).await;
            assert!(exists_result.is_ok(), "Failed to check existence of key '{}' for backend {}: {:?}", 
                    key.escape_debug(), backend_name, exists_result);
            assert!(exists_result.unwrap(), "Key '{}' should exist in backend {}", 
                    key.escape_debug(), backend_name);
            
            // Test delete operation
            // æµ‹è¯•åˆ é™¤æ“ä½œ
            let delete_result = store.delete(&key.to_string()).await;
            assert!(delete_result.is_ok(), "Failed to delete key '{}' for backend {}: {:?}", 
                    key.escape_debug(), backend_name, delete_result);
            
            // Verify deletion
            // éªŒè¯åˆ é™¤
            let after_delete = store.get(&key.to_string()).await.unwrap();
            assert_eq!(after_delete, None, "Key '{}' should be deleted from backend {}", 
                      key.escape_debug(), backend_name);
        }
        
        println!("Backend {} passed empty and whitespace keys test", backend_name);
    }
}

/// Test problematic values
/// æµ‹è¯•é—®é¢˜å€¼
#[tokio::test]
async fn test_problematic_values() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing problematic values for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        let problematic_values = test_utils::generate_problematic_values();
        
        for (i, value) in problematic_values.iter().enumerate() {
            let key = format!("problematic_value_key_{}", i);
            
            // Test put operation with timeout for large values
            // å¯¹å¤§å€¼ä½¿ç”¨è¶…æ—¶æµ‹è¯•è®¾ç½®æ“ä½œ
            let value_bytes = value.as_bytes().to_vec();
            let put_result = timeout(Duration::from_secs(30), store.put(&key, &value_bytes)).await;
            assert!(put_result.is_ok(), "Timeout putting problematic value {} for backend {}", 
                    i, backend_name);
            assert!(put_result.unwrap().is_ok(), "Failed to put problematic value {} for backend {}", 
                    i, backend_name);
            
            // Test get operation with timeout for large values
            // å¯¹å¤§å€¼ä½¿ç”¨è¶…æ—¶æµ‹è¯•è·å–æ“ä½œ
            let get_result = timeout(Duration::from_secs(30), store.get(&key)).await;
            assert!(get_result.is_ok(), "Timeout getting problematic value {} for backend {}", 
                    i, backend_name);
            
            let retrieved_value = get_result.unwrap().unwrap();
            assert_eq!(retrieved_value, Some(value.as_bytes().to_vec()), 
                      "Value mismatch for problematic value {} in backend {}", i, backend_name);
            
            // Clean up large values to avoid memory issues
            // æ¸…ç†å¤§å€¼ä»¥é¿å…å†…å­˜é—®é¢˜
            if value.len() > 1024 * 1024 {
                store.delete(&key).await.unwrap();
            }
        }
        
        println!("Backend {} passed problematic values test", backend_name);
    }
}

/// Test very large keys and values
/// æµ‹è¯•éå¸¸å¤§çš„é”®å’Œå€¼
#[tokio::test]
async fn test_very_large_keys_and_values() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing very large keys and values for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test very long key (but reasonable value)
        // æµ‹è¯•å¾ˆé•¿çš„é”®ï¼ˆä½†åˆç†çš„å€¼ï¼‰
        let very_long_key = "x".repeat(10000);
        let normal_value = "normal_value";
        
        let normal_value_bytes = normal_value.as_bytes().to_vec();
        let result = store.put(&very_long_key, &normal_value_bytes).await;
        assert!(result.is_ok(), "Failed to put very long key for backend {}: {:?}", 
                backend_name, result);
        
        let retrieved = store.get(&very_long_key).await.unwrap();
        assert_eq!(retrieved, Some(normal_value.as_bytes().to_vec()));
        
        // Test normal key with very large value (100MB)
        // æµ‹è¯•æ™®é€šé”®ä¸éå¸¸å¤§çš„å€¼ï¼ˆ100MBï¼‰
        let normal_key = "normal_key_large_value";
        let very_large_value = "z".repeat(100 * 1024 * 1024); // 100MB
        
        let very_large_value_bytes = very_large_value.as_bytes().to_vec();
        let result = timeout(Duration::from_secs(60), store.put(&normal_key.to_string(), &very_large_value_bytes)).await;
        if result.is_ok() && result.unwrap().is_ok() {
            println!("Backend {} successfully stored 100MB value", backend_name);
            
            // Try to retrieve it
            // å°è¯•æ£€ç´¢å®ƒ
            let get_result = timeout(Duration::from_secs(60), store.get(&normal_key.to_string())).await;
            if get_result.is_ok() {
                let retrieved = get_result.unwrap().unwrap();
                assert_eq!(retrieved, Some(very_large_value.as_bytes().to_vec()));
                println!("Backend {} successfully retrieved 100MB value", backend_name);
            } else {
                println!("Backend {} timed out retrieving 100MB value", backend_name);
            }
            
            // Clean up
            // æ¸…ç†
            store.delete(&normal_key.to_string()).await.unwrap();
        } else {
            println!("Backend {} cannot handle 100MB values (expected for some backends)", backend_name);
        }
        
        // Clean up
        // æ¸…ç†
        store.delete(&very_long_key).await.unwrap();
        
        println!("Backend {} completed large keys and values test", backend_name);
    }
}

/// Test concurrent access to the same key
/// æµ‹è¯•å¯¹åŒä¸€é”®çš„å¹¶å‘è®¿é—®
#[tokio::test]
async fn test_concurrent_same_key_access() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing concurrent same key access for backend: {}", backend_name);
        
        let store = Arc::new(factory.create(&config).await.unwrap());
        let key = "concurrent_test_key";
        
        // Test concurrent writes to the same key
        // æµ‹è¯•å¯¹åŒä¸€é”®çš„å¹¶å‘å†™å…¥
        let write_handles: Vec<_> = (0..10).map(|i| {
            let store_clone = Arc::clone(&store);
            let key = key.to_string();
            tokio::spawn(async move {
                for j in 0..100 {
                    let value = format!("value_{}_{}", i, j);
                    let value_bytes = value.as_bytes().to_vec();
                    store_clone.put(&key, &value_bytes).await.unwrap();
                }
            })
        }).collect();
        
        // Wait for all writes to complete
        // ç­‰å¾…æ‰€æœ‰å†™å…¥å®Œæˆ
        for handle in write_handles {
            handle.await.unwrap();
        }
        
        // Verify the key exists and has some value
        // éªŒè¯é”®å­˜åœ¨å¹¶æœ‰æŸä¸ªå€¼
        let final_value = store.get(&key.to_string()).await.unwrap();
        assert!(final_value.is_some(), "Key should exist after concurrent writes in backend {}", backend_name);
        
        // Test concurrent reads of the same key
        // æµ‹è¯•å¯¹åŒä¸€é”®çš„å¹¶å‘è¯»å–
        let read_handles: Vec<_> = (0..10).map(|_| {
            let store_clone = Arc::clone(&store);
            let key = key.to_string();
            tokio::spawn(async move {
                for _ in 0..100 {
                    let _value = store_clone.get(&key).await.unwrap();
                }
            })
        }).collect();
        
        // Wait for all reads to complete
        // ç­‰å¾…æ‰€æœ‰è¯»å–å®Œæˆ
        for handle in read_handles {
            handle.await.unwrap();
        }
        
        // Test mixed concurrent operations
        // æµ‹è¯•æ··åˆå¹¶å‘æ“ä½œ
        let mixed_handles: Vec<_> = (0..5).map(|i| {
            let store_clone = Arc::clone(&store);
            let key = key.to_string();
            tokio::spawn(async move {
                for j in 0..50 {
                    match j % 3 {
                        0 => {
                            let value = format!("mixed_value_{}_{}", i, j);
                            let value_bytes = value.as_bytes().to_vec();
                            store_clone.put(&key, &value_bytes).await.unwrap();
                        },
                        1 => {
                            let _value = store_clone.get(&key).await.unwrap();
                        },
                        2 => {
                            let _exists = store_clone.exists(&key).await.unwrap();
                        },
                        _ => unreachable!(),
                    }
                }
            })
        }).collect();
        
        // Wait for all mixed operations to complete
        // ç­‰å¾…æ‰€æœ‰æ··åˆæ“ä½œå®Œæˆ
        for handle in mixed_handles {
            handle.await.unwrap();
        }
        
        // Clean up
        // æ¸…ç†
        store.delete(&key.to_string()).await.unwrap();
        
        println!("Backend {} passed concurrent same key access test", backend_name);
    }
}

/// Test rapid key creation and deletion
/// æµ‹è¯•å¿«é€Ÿé”®åˆ›å»ºå’Œåˆ é™¤
#[tokio::test]
async fn test_rapid_key_creation_deletion() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing rapid key creation and deletion for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Rapidly create and delete keys
        // å¿«é€Ÿåˆ›å»ºå’Œåˆ é™¤é”®
        for cycle in 0..10 {
            // Create many keys
            // åˆ›å»ºè®¸å¤šé”®
            for i in 0..1000 {
                let key = format!("rapid_key_{}_{}", cycle, i);
                let value = format!("rapid_value_{}_{}", cycle, i);
                let value_bytes = value.as_bytes().to_vec();
                store.put(&key, &value_bytes).await.unwrap();
            }
            
            // Verify they exist
            // éªŒè¯å®ƒä»¬å­˜åœ¨
            for i in 0..1000 {
                let key = format!("rapid_key_{}_{}", cycle, i);
                let exists = store.exists(&key).await.unwrap();
                assert!(exists, "Key {} should exist in cycle {} for backend {}", 
                        key, cycle, backend_name);
            }
            
            // Delete them all
            // åˆ é™¤æ‰€æœ‰é”®
            for i in 0..1000 {
                let key = format!("rapid_key_{}_{}", cycle, i);
                store.delete(&key).await.unwrap();
            }
            
            // Verify they're gone
            // éªŒè¯å®ƒä»¬å·²æ¶ˆå¤±
            for i in 0..1000 {
                let key = format!("rapid_key_{}_{}", cycle, i);
                let exists = store.exists(&key).await.unwrap();
                assert!(!exists, "Key {} should not exist after deletion in cycle {} for backend {}", 
                        key, cycle, backend_name);
            }
        }
        
        println!("Backend {} passed rapid key creation and deletion test", backend_name);
    }
}

/// Test scan operations with edge cases
/// æµ‹è¯•å¸¦è¾¹ç•Œæƒ…å†µçš„æ‰«ææ“ä½œ
#[tokio::test]
async fn test_scan_operations_edge_cases() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing scan operations edge cases for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test scanning with no matching keys
        // æµ‹è¯•æ²¡æœ‰åŒ¹é…é”®çš„æ‰«æ
        let empty_scan = store.keys_with_prefix("nonexistent_prefix").await.unwrap();
        assert_eq!(empty_scan.len(), 0);
        
        let empty_scan_pairs = store.scan_prefix("nonexistent_prefix").await.unwrap();
        assert_eq!(empty_scan_pairs.len(), 0);
        
        // Test scanning with empty prefix
        // æµ‹è¯•ç©ºå‰ç¼€çš„æ‰«æ
        let all_keys_scan = store.keys_with_prefix("").await.unwrap();
        let all_pairs_scan = store.scan_prefix("").await.unwrap();
        assert_eq!(all_keys_scan.len(), all_pairs_scan.len());
        
        // Add test data with overlapping prefixes
        // æ·»åŠ å…·æœ‰é‡å å‰ç¼€çš„æµ‹è¯•æ•°æ®
        let test_keys = vec![
            "a", "aa", "aaa", "aaaa",
            "ab", "abb", "abbb",
            "b", "ba", "baa",
            "prefix", "prefix_1", "prefix_12", "prefix_123",
        ];
        
        for key in &test_keys {
            let value = format!("value_for_{}", key);
            let value_bytes = value.as_bytes().to_vec();
            store.put(&key.to_string(), &value_bytes).await.unwrap();
        }
        
        // Test prefix scanning with overlapping prefixes
        // æµ‹è¯•é‡å å‰ç¼€çš„å‰ç¼€æ‰«æ
        let a_keys = store.keys_with_prefix("a").await.unwrap();
        assert!(a_keys.len() >= 7); // Should include a, aa, aaa, aaaa, ab, abb, abbb
        
        let aa_keys = store.keys_with_prefix("aa").await.unwrap();
        assert!(aa_keys.len() >= 3); // Should include aa, aaa, aaaa
        
        let prefix_keys = store.keys_with_prefix("prefix").await.unwrap();
        assert!(prefix_keys.len() >= 4); // Should include prefix, prefix_1, prefix_12, prefix_123
        
        // Test range operations with edge cases
        // æµ‹è¯•è¾¹ç•Œæƒ…å†µçš„èŒƒå›´æ“ä½œ
        let range_options = spear_next::storage::RangeOptions {
             start_key: Some("a".to_string()),
             end_key: Some("b".to_string()),
             limit: None,
             reverse: false,
         };
         let range_result = store.range(&range_options).await.unwrap();
         assert!(range_result.len() > 0);
         
         // Test range with same start and end
         // æµ‹è¯•ç›¸åŒå¼€å§‹å’Œç»“æŸçš„èŒƒå›´
         let empty_range_options = spear_next::storage::RangeOptions {
             start_key: Some("a".to_string()),
             end_key: Some("a".to_string()),
             limit: None,
             reverse: false,
         };
         let empty_range = store.range(&empty_range_options).await.unwrap();
         assert_eq!(empty_range.len(), 0);
         
         // Test range with inverted order (end < start)
         // æµ‹è¯•å€’åºèŒƒå›´ï¼ˆç»“æŸ < å¼€å§‹ï¼‰
         let inverted_range_options = spear_next::storage::RangeOptions {
             start_key: Some("z".to_string()),
             end_key: Some("a".to_string()),
             limit: None,
             reverse: false,
         };
        let inverted_range = store.range(&inverted_range_options).await.unwrap();
        assert_eq!(inverted_range.len(), 0);
        
        // Clean up
        // æ¸…ç†
        for key in &test_keys {
            store.delete(&key.to_string()).await.unwrap();
        }
        
        println!("Backend {} passed scan operations edge cases test", backend_name);
    }
}

/// Test memory pressure and resource limits
/// æµ‹è¯•å†…å­˜å‹åŠ›å’Œèµ„æºé™åˆ¶
#[tokio::test]
async fn test_memory_pressure_and_limits() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing memory pressure and limits for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test storing many small keys
        // æµ‹è¯•å­˜å‚¨è®¸å¤šå°é”®
        let num_keys = 10000;
        for i in 0..num_keys {
            let key = format!("memory_test_key_{:06}", i);
            let value = format!("memory_test_value_{:06}", i);
            let value_bytes = value.as_bytes().to_vec();
            store.put(&key, &value_bytes).await.unwrap();
        }
        
        // Verify all keys exist
        // éªŒè¯æ‰€æœ‰é”®å­˜åœ¨
        let all_keys = store.keys_with_prefix("memory_test_key_").await.unwrap();
        assert_eq!(all_keys.len(), num_keys);
        
        // Test batch retrieval
        // æµ‹è¯•æ‰¹é‡æ£€ç´¢
        for i in 0..num_keys {
            let key = format!("memory_test_key_{:06}", i);
            let value = store.get(&key).await.unwrap();
            assert!(value.is_some());
        }
        
        // Clean up in batches to test deletion performance
        // æ‰¹é‡æ¸…ç†ä»¥æµ‹è¯•åˆ é™¤æ€§èƒ½
        for batch_start in (0..num_keys).step_by(1000) {
            for i in batch_start..std::cmp::min(batch_start + 1000, num_keys) {
                let key = format!("memory_test_key_{:06}", i);
                store.delete(&key).await.unwrap();
            }
        }
        
        // Verify cleanup
        // éªŒè¯æ¸…ç†
        let remaining_keys = store.keys_with_prefix("memory_test_key_").await.unwrap();
        assert_eq!(remaining_keys.len(), 0);
        
        println!("Backend {} passed memory pressure and limits test", backend_name);
    }
}