//! KV Storage Integration Tests
//! KVå­˜å‚¨é›†æˆæµ‹è¯•
//!
//! This module contains comprehensive integration tests for the KV storage layer,
//! including performance tests, error handling, concurrent operations, and cross-backend compatibility.
//! æ­¤æ¨¡å—åŒ…å«KVå­˜å‚¨å±‚çš„ç»¼åˆé›†æˆæµ‹è¯•ï¼ŒåŒ…æ‹¬æ€§èƒ½æµ‹è¯•ã€é”™è¯¯å¤„ç†ã€å¹¶å‘æ“ä½œå’Œè·¨åç«¯å…¼å®¹æ€§ã€‚

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::Barrier;
use tokio::time::timeout;
use uuid::Uuid;

use spear_next::storage::{KvStoreConfig, DefaultKvStoreFactory, KvStoreFactory, RangeOptions};


/// Test utilities for KV storage integration tests
/// KVå­˜å‚¨é›†æˆæµ‹è¯•çš„æµ‹è¯•å·¥å…·
mod test_utils {
    use super::*;
    use tempfile::TempDir;

    /// Create test configurations for all supported backends
    /// ä¸ºæ‰€æœ‰æ”¯æŒçš„åç«¯åˆ›å»ºæµ‹è¯•é…ç½®
    pub fn create_test_configs() -> Vec<(&'static str, KvStoreConfig, Option<TempDir>)> {
        let configs = vec![
            ("memory", KvStoreConfig::memory(), None),
        ];

        // Add Sled configuration with temporary directory
        // æ·»åŠ å¸¦ä¸´æ—¶ç›®å½•çš„Sledé…ç½®
        #[cfg(feature = "sled")]
        {
            let temp_dir = TempDir::new().unwrap();
            let sled_config = KvStoreConfig::sled(temp_dir.path().to_str().unwrap());
            configs.push(("sled", sled_config, Some(temp_dir)));
        }

        // Add RocksDB configuration with temporary directory
        // æ·»åŠ å¸¦ä¸´æ—¶ç›®å½•çš„RocksDBé…ç½®
        #[cfg(feature = "rocksdb")]
        {
            let temp_dir = TempDir::new().unwrap();
            let rocksdb_config = KvStoreConfig::rocksdb(temp_dir.path().to_str().unwrap());
            configs.push(("rocksdb", rocksdb_config, Some(temp_dir)));
        }

        configs
    }

    /// Generate test data for performance tests
    /// ä¸ºæ€§èƒ½æµ‹è¯•ç”Ÿæˆæµ‹è¯•æ•°æ®
    pub fn generate_test_data(count: usize) -> Vec<(String, String)> {
        (0..count)
            .map(|i| (format!("key_{:06}", i), format!("value_{:06}_{}", i, Uuid::new_v4())))
            .collect()
    }

    /// Generate large test data for stress tests
    /// ä¸ºå‹åŠ›æµ‹è¯•ç”Ÿæˆå¤§é‡æµ‹è¯•æ•°æ®
    pub fn generate_large_test_data(count: usize, value_size: usize) -> Vec<(String, String)> {
        let large_value = "x".repeat(value_size);
        (0..count)
            .map(|i| (format!("large_key_{:06}", i), format!("{}_{}_{}", large_value, i, Uuid::new_v4())))
            .collect()
    }
}

/// Test cross-backend compatibility
/// æµ‹è¯•è·¨åç«¯å…¼å®¹æ€§
#[tokio::test]
async fn test_cross_backend_compatibility() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();

    for (backend_name, config, _temp_dir) in configs {
        println!("Testing backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test basic operations
        // æµ‹è¯•åŸºæœ¬æ“ä½œ
        let key = "compatibility_test_key";
        let value = "compatibility_test_value";
        
        store.put(&key.to_string(), &value.as_bytes().to_vec()).await.unwrap();
        let retrieved = store.get(&key.to_string()).await.unwrap();
        assert_eq!(retrieved, Some(value.as_bytes().to_vec()));
        
        let exists = store.exists(&key.to_string()).await.unwrap();
        assert!(exists);
        
        store.delete(&key.to_string()).await.unwrap();
        let after_delete = store.get(&key.to_string()).await.unwrap();
        assert_eq!(after_delete, None);
        
        println!("Backend {} passed compatibility test", backend_name);
    }
}

/// Test performance comparison across backends
/// æµ‹è¯•è·¨åç«¯æ€§èƒ½æ¯”è¾ƒ
#[tokio::test]
async fn test_performance_comparison() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();
    let test_data = test_utils::generate_test_data(1000);
    
    let mut results = HashMap::new();
    
    for (backend_name, config, _temp_dir) in configs {
        println!("Performance testing backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test write performance
        // æµ‹è¯•å†™å…¥æ€§èƒ½
        let start = Instant::now();
        for (key, value) in &test_data {
            store.put(key, &value.as_bytes().to_vec()).await.unwrap();
        }
        let write_duration = start.elapsed();
        
        // Test read performance
        // æµ‹è¯•è¯»å–æ€§èƒ½
        let start = Instant::now();
        for (key, _) in &test_data {
            let _ = store.get(key).await.unwrap();
        }
        let read_duration = start.elapsed();
        
        // Test scan performance
        // æµ‹è¯•æ‰«ææ€§èƒ½
        let start = Instant::now();
        let keys = store.keys_with_prefix("key_").await.unwrap();
        let scan_duration = start.elapsed();
        
        results.insert(backend_name, (write_duration, read_duration, scan_duration, keys.len()));
        
        println!(
            "Backend {}: Write: {:?}, Read: {:?}, Scan: {:?}, Keys: {}",
            backend_name, write_duration, read_duration, scan_duration, keys.len()
        );
    }
    
    // Verify all backends returned the same number of keys
    // éªŒè¯æ‰€æœ‰åç«¯è¿”å›ç›¸åŒæ•°é‡çš„é”®
    let key_counts: Vec<usize> = results.values().map(|(_, _, _, count)| *count).collect();
    assert!(key_counts.iter().all(|&count| count == test_data.len()));
}

/// Test concurrent operations
/// æµ‹è¯•å¹¶å‘æ“ä½œ
#[tokio::test]
async fn test_concurrent_operations() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();
    
    for (backend_name, config, _temp_dir) in configs {
        println!("Testing concurrent operations for backend: {}", backend_name);
        
        let store = Arc::new(factory.create(&config).await.unwrap());
        let num_tasks = 10;
        let operations_per_task = 100;
        let barrier = Arc::new(Barrier::new(num_tasks));
        
        let mut handles = vec![];
        
        for task_id in 0..num_tasks {
            let store_clone = Arc::clone(&store);
            let barrier_clone = Arc::clone(&barrier);
            
            let handle = tokio::spawn(async move {
                // Wait for all tasks to be ready
                // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å‡†å¤‡å°±ç»ª
                barrier_clone.wait().await;
                
                for op_id in 0..operations_per_task {
                    let key = format!("concurrent_{}_{}", task_id, op_id);
                    let value = format!("value_{}_{}", task_id, op_id);
                    
                    // Perform set operation
                    // æ‰§è¡Œè®¾ç½®æ“ä½œ
                    store_clone.put(&key, &value.as_bytes().to_vec()).await.unwrap();
                    
                    // Verify get operation
                    // éªŒè¯è·å–æ“ä½œ
                    let retrieved = store_clone.get(&key).await.unwrap();
                    assert_eq!(retrieved, Some(value.as_bytes().to_vec()));
                    
                    // Test exists operation
                    // æµ‹è¯•å­˜åœ¨æ€§æ“ä½œ
                    let exists = store_clone.exists(&key).await.unwrap();
                    assert!(exists);
                }
            });
            
            handles.push(handle);
        }
        
        // Wait for all tasks to complete
        // ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for handle in handles {
            handle.await.unwrap();
        }
        
        // Verify total number of keys
        // éªŒè¯é”®çš„æ€»æ•°
        let all_keys = store.keys_with_prefix("concurrent_").await.unwrap();
        assert_eq!(all_keys.len(), num_tasks * operations_per_task);
        
        println!("Backend {} passed concurrent operations test", backend_name);
    }
}

/// Test error handling and edge cases
/// æµ‹è¯•é”™è¯¯å¤„ç†å’Œè¾¹ç•Œæƒ…å†µ
#[tokio::test]
async fn test_error_handling_and_edge_cases() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();
    
    for (backend_name, config, _temp_dir) in configs {
        println!("Testing error handling for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test empty key handling
        // æµ‹è¯•ç©ºé”®å¤„ç†
        let result = store.put(&"".to_string(), &"value".as_bytes().to_vec()).await;
        // Should succeed for most backends
        // å¯¹å¤§å¤šæ•°åç«¯åº”è¯¥æˆåŠŸ
        assert!(result.is_ok());
        
        // Test empty value handling
        // æµ‹è¯•ç©ºå€¼å¤„ç†
        let result = store.put(&"key".to_string(), &"".as_bytes().to_vec()).await;
        assert!(result.is_ok());
        
        let retrieved = store.get(&"key".to_string()).await.unwrap();
        assert_eq!(retrieved, Some("".as_bytes().to_vec()));
        
        // Test very long key
        // æµ‹è¯•å¾ˆé•¿çš„é”®
        let long_key = "x".repeat(1000);
        let result = store.put(&long_key, &"value".as_bytes().to_vec()).await;
        assert!(result.is_ok());
        
        // Test very long value
        // æµ‹è¯•å¾ˆé•¿çš„å€¼
        let long_value = "y".repeat(10000);
        let result = store.put(&"long_value_key".to_string(), &long_value.as_bytes().to_vec()).await;
        assert!(result.is_ok());
        
        let retrieved = store.get(&"long_value_key".to_string()).await.unwrap();
        assert_eq!(retrieved, Some(long_value.as_bytes().to_vec()));
        
        // Test special characters in keys and values
        // æµ‹è¯•é”®å’Œå€¼ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        let special_key = "key/with\\special:chars@#$%^&*()";
        let special_value = "value\nwith\ttabs\rand\0nulls";
        let result = store.put(&special_key.to_string(), &special_value.as_bytes().to_vec()).await;
        assert!(result.is_ok());
        
        let retrieved = store.get(&special_key.to_string()).await.unwrap();
        assert_eq!(retrieved, Some(special_value.as_bytes().to_vec()));
        
        // Test Unicode characters
        // æµ‹è¯•Unicodeå­—ç¬¦
        let unicode_key = "é”®_ğŸ”‘_key";
        let unicode_value = "å€¼_ğŸ’_value_ä¸­æ–‡";
        let result = store.put(&unicode_key.to_string(), &unicode_value.as_bytes().to_vec()).await;
        assert!(result.is_ok());
        
        let retrieved = store.get(&unicode_key.to_string()).await.unwrap();
        assert_eq!(retrieved, Some(unicode_value.as_bytes().to_vec()));
        
        println!("Backend {} passed error handling test", backend_name);
    }
}

/// Test large data handling and stress scenarios
/// æµ‹è¯•å¤§æ•°æ®å¤„ç†å’Œå‹åŠ›åœºæ™¯
#[tokio::test]
async fn test_large_data_handling() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();
    
    for (backend_name, config, _temp_dir) in configs {
        println!("Testing large data handling for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Test with large values (1MB each)
        // æµ‹è¯•å¤§å€¼ï¼ˆæ¯ä¸ª1MBï¼‰
        let large_data = test_utils::generate_large_test_data(10, 1024 * 1024);
        
        for (key, value) in &large_data {
            let result = timeout(Duration::from_secs(30), store.put(key, &value.as_bytes().to_vec())).await;
            assert!(result.is_ok(), "Timeout or error setting large value for backend {}", backend_name);
            assert!(result.unwrap().is_ok());
        }
        
        // Verify large values can be retrieved
        // éªŒè¯å¯ä»¥æ£€ç´¢å¤§å€¼
        for (key, expected_value) in &large_data {
            let result = timeout(Duration::from_secs(30), store.get(key)).await;
            assert!(result.is_ok(), "Timeout getting large value for backend {}", backend_name);
            
            let retrieved = result.unwrap().unwrap();
            assert_eq!(retrieved, Some(expected_value.as_bytes().to_vec()));
        }
        
        // Test batch operations with large data
        // æµ‹è¯•å¤§æ•°æ®çš„æ‰¹é‡æ“ä½œ
        let _keys: Vec<String> = large_data.iter().map(|(k, _)| k.clone()).collect();
        let scan_result = timeout(Duration::from_secs(30), store.keys_with_prefix("large_key_")).await;
        assert!(scan_result.is_ok(), "Timeout scanning large data for backend {}", backend_name);
        
        let scanned_keys = scan_result.unwrap().unwrap();
        assert_eq!(scanned_keys.len(), large_data.len());
        
        println!("Backend {} passed large data handling test", backend_name);
    }
}

/// Test range operations across different backends
/// æµ‹è¯•è·¨ä¸åŒåç«¯çš„èŒƒå›´æ“ä½œ
#[tokio::test]
async fn test_range_operations_comprehensive() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();
    
    for (backend_name, config, _temp_dir) in configs {
        println!("Testing range operations for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Setup test data with predictable ordering
        // è®¾ç½®å…·æœ‰å¯é¢„æµ‹æ’åºçš„æµ‹è¯•æ•°æ®
        let test_data = vec![
            ("a001", "value_a001"),
            ("a002", "value_a002"),
            ("a010", "value_a010"),
            ("b001", "value_b001"),
            ("b002", "value_b002"),
            ("c001", "value_c001"),
        ];
        
        for (key, value) in &test_data {
            store.put(&key.to_string(), &value.as_bytes().to_vec()).await.unwrap();
        }
        
        // Test prefix scanning
        // æµ‹è¯•å‰ç¼€æ‰«æ
        let a_keys = store.keys_with_prefix("a").await.unwrap();
        assert_eq!(a_keys.len(), 3);
        assert!(a_keys.contains(&"a001".to_string()));
        assert!(a_keys.contains(&"a002".to_string()));
        assert!(a_keys.contains(&"a010".to_string()));
        
        let b_keys = store.keys_with_prefix("b").await.unwrap();
        assert_eq!(b_keys.len(), 2);
        
        // Test scan_prefix with key-value pairs
        // æµ‹è¯•å¸¦é”®å€¼å¯¹çš„scan_prefix
        let a_pairs = store.scan_prefix("a").await.unwrap();
        assert_eq!(a_pairs.len(), 3);
        
        for pair in &a_pairs {
            assert!(pair.key.starts_with("a"));
            let value_str = String::from_utf8(pair.value.clone()).unwrap();
            assert!(value_str.starts_with("value_a"));
        }
        
        // Test range operations
        // æµ‹è¯•èŒƒå›´æ“ä½œ
        let range_options = RangeOptions::new()
            .start_key("a001")
            .end_key("b001");
        let range_pairs = store.range(&range_options).await.unwrap();
        // Should include a001, a002, a010 but not b001 (exclusive end)
        // åº”è¯¥åŒ…æ‹¬a001, a002, a010ä½†ä¸åŒ…æ‹¬b001ï¼ˆæ’ä»–æ€§ç»“æŸï¼‰
        assert!(range_pairs.len() >= 3);
        
        println!("Backend {} passed range operations test", backend_name);
    }
}

/// Test factory configuration and validation
/// æµ‹è¯•å·¥å‚é…ç½®å’ŒéªŒè¯
#[tokio::test]
async fn test_factory_configuration_validation() {
    let factory = DefaultKvStoreFactory::new();
    
    // Test memory configuration
    // æµ‹è¯•å†…å­˜é…ç½®
    let memory_config = KvStoreConfig::memory();
    let memory_store = factory.create(&memory_config).await;
    assert!(memory_store.is_ok());
    
    // Test invalid path configurations (should still work but may create directories)
    // æµ‹è¯•æ— æ•ˆè·¯å¾„é…ç½®ï¼ˆåº”è¯¥ä»ç„¶å·¥ä½œä½†å¯èƒ½åˆ›å»ºç›®å½•ï¼‰
    #[cfg(feature = "sled")]
    {
        let sled_config = KvStoreConfig::sled("/tmp/test_sled_factory");
        let sled_store = factory.create(&sled_config).await;
        assert!(sled_store.is_ok());
    }
    
    #[cfg(feature = "rocksdb")]
    {
        let rocksdb_config = KvStoreConfig::rocksdb("/tmp/test_rocksdb_factory");
        let rocksdb_store = factory.create(&rocksdb_config).await;
        assert!(rocksdb_store.is_ok());
    }
}

/// Test cleanup and resource management
/// æµ‹è¯•æ¸…ç†å’Œèµ„æºç®¡ç†
#[tokio::test]
async fn test_cleanup_and_resource_management() {
    let factory = DefaultKvStoreFactory::new();
    let configs = test_utils::create_test_configs();
    
    for (backend_name, config, _temp_dir) in configs {
        println!("Testing cleanup for backend: {}", backend_name);
        
        let store = factory.create(&config).await.unwrap();
        
        // Add some test data
        // æ·»åŠ ä¸€äº›æµ‹è¯•æ•°æ®
        for i in 0..100 {
            let key = format!("cleanup_test_{}", i);
            let value = format!("value_{}", i);
            store.put(&key, &value.as_bytes().to_vec()).await.unwrap();
        }
        
        // Verify data exists
        // éªŒè¯æ•°æ®å­˜åœ¨
        let keys = store.keys_with_prefix("cleanup_test_").await.unwrap();
        assert_eq!(keys.len(), 100);
        
        // Delete all test data
        // åˆ é™¤æ‰€æœ‰æµ‹è¯•æ•°æ®
        for key in &keys {
            store.delete(key).await.unwrap();
        }
        
        // Verify data is deleted
        // éªŒè¯æ•°æ®å·²åˆ é™¤
        let remaining_keys = store.keys_with_prefix("cleanup_test_").await.unwrap();
        assert_eq!(remaining_keys.len(), 0);
        
        println!("Backend {} passed cleanup test", backend_name);
    }
}